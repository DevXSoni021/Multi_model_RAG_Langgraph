{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö Multi-modal PDF RAG with LangGraph - Complete Google Colab Guide\n",
        "\n",
        "**Run this on GPU for best performance!**\n",
        "\n",
        "This notebook provides a complete multi-modal RAG system that can:\n",
        "- Process PDFs with text, images, and tables\n",
        "- Perform semantic search on both text and images  \n",
        "- Answer questions using a multi-agent system\n",
        "- Use Hugging Face models (free, no OpenAI required)\n",
        "\n",
        "## ‚öôÔ∏è Setup Steps:\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or better)\n",
        "2. **Hugging Face API key (OPTIONAL)**: https://huggingface.co/settings/tokens\n",
        "   - Note: We use **local models** by default, so API key is not required!\n",
        "   - Only needed if you want to use Hugging Face API for some features\n",
        "3. **Run all cells in order** (Step 1 ‚Üí Step 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install All Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 0.1.0 not found\n",
            "zsh:1: no matches found: unstructured[pdf]\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.72 requires langchain<0.0.337,>=0.0.336, but you have langchain 0.3.27 which is incompatible.\n",
            "embedchain 0.1.72 requires pypdf<4.0.0,>=3.11.0, but you have pypdf 6.4.0 which is incompatible.\n",
            "embedchain 0.1.72 requires tiktoken<0.5.0,>=0.4.0, but you have tiktoken 0.9.0 which is incompatible.\n",
            "langchain-chroma 0.2.4 requires chromadb>=1.0.9, but you have chromadb 0.4.24 which is incompatible.\n",
            "onnx 1.19.1 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "streamlit 1.28.0 requires numpy<2,>=1.19.3, but you have numpy 2.0.2 which is incompatible.\n",
            "streamlit 1.28.0 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "zsh:1: 2.7.4, not found\n",
            "zsh:1: command not found: apt-get\n",
            "zsh:1: command not found: apt-get\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "!pip install -q langchain>=0.1.0 langchain-openai>=0.0.2 langchain-community>=0.0.10 langgraph>=0.0.20\n",
        "!pip install -q unstructured[pdf] pypdf pdf2image Pillow\n",
        "!pip install -q chromadb faiss-cpu\n",
        "!pip install -q sentence-transformers torch torchvision\n",
        "!pip install -q duckduckgo-search tavily-python\n",
        "!pip install -q python-dotenv requests opencv-python\n",
        "!pip install -q numpy==1.24.3 pydantic>=2.7.4,<3.0.0\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq poppler-utils tesseract-ocr\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Set Your API Keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ API keys configured!\n",
            "‚úì Hugging Face API key set: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ‚ö†Ô∏è REPLACE WITH YOUR ACTUAL API KEYS ‚ö†Ô∏è\n",
        "# Note: Hugging Face API key is OPTIONAL - we use local models (no API needed)\n",
        "# Only needed if you want to use Hugging Face API for some features\n",
        "HUGGINGFACE_API_KEY = \"YOUR_HUGGINGFACE_API_KEY_HERE\"  # Optional - Get from https://huggingface.co/settings/tokens\n",
        "TAVILY_API_KEY = \"YOUR_TAVILY_API_KEY_HERE\"  # Optional - For web search\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
        "os.environ[\"USE_HUGGINGFACE_PRIMARY\"] = \"true\"\n",
        "os.environ[\"USE_OPENAI_EMBEDDINGS\"] = \"false\"\n",
        "os.environ[\"USE_OPENAI_FALLBACK\"] = \"false\"\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "\n",
        "print(\"‚úÖ API keys configured!\")\n",
        "print(f\"‚úì Hugging Face API key set: {bool(HUGGINGFACE_API_KEY and HUGGINGFACE_API_KEY != 'YOUR_HUGGINGFACE_API_KEY_HERE')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Configuration File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created config.py\n"
          ]
        }
      ],
      "source": [
        "# Create config.py\n",
        "config_code = '''\"\"\"Configuration settings for the Multi-modal RAG system.\"\"\"\n",
        "import os\n",
        "\n",
        "# API Keys\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\", \"\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
        "\n",
        "# Model Configuration\n",
        "LLM_MODEL = \"gpt-4-1106-preview\"\n",
        "VISION_MODEL = \"gpt-4-vision-preview\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
        "\n",
        "# Hugging Face Configuration\n",
        "HUGGINGFACE_LLM_MODEL = os.getenv(\"HUGGINGFACE_LLM_MODEL\", \"distilgpt2\")  # Use distilgpt2 for faster local loading\n",
        "HUGGINGFACE_MULTIMODAL_MODEL = \"Salesforce/blip-image-captioning-large\"\n",
        "USE_HUGGINGFACE_PRIMARY = os.getenv(\"USE_HUGGINGFACE_PRIMARY\", \"true\").lower() == \"true\"\n",
        "USE_OPENAI_EMBEDDINGS = os.getenv(\"USE_OPENAI_EMBEDDINGS\", \"false\").lower() == \"true\"\n",
        "USE_OPENAI_FALLBACK = os.getenv(\"USE_OPENAI_FALLBACK\", \"false\").lower() == \"true\"\n",
        "\n",
        "# Vector Store Configuration\n",
        "VECTOR_STORE_PATH = os.getenv(\"VECTOR_STORE_PATH\", \"./vector_store\")\n",
        "CHROMA_COLLECTION_NAME = \"multimodal_pdf_rag\"\n",
        "MAX_RETRIEVAL_DOCS = 3\n",
        "MAX_IMAGES_PER_QUERY = 2\n",
        "\n",
        "# PDF Processing Configuration\n",
        "PDF_PROCESSING_MODE = \"hi_res\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "# Agent Configuration\n",
        "MAX_ITERATIONS = 30\n",
        "TEMPERATURE = 0.0\n",
        "\n",
        "# Rate Limit Configuration\n",
        "MAX_RETRIES = 3\n",
        "RETRY_DELAY_SECONDS = 2\n",
        "'''\n",
        "\n",
        "with open('config.py', 'w') as f:\n",
        "    f.write(config_code)\n",
        "\n",
        "print(\"‚úÖ Created config.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Image Embeddings Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created image_embeddings.py\n"
          ]
        }
      ],
      "source": [
        "# Create image_embeddings.py\n",
        "image_embeddings_code = '''\"\"\"Image embedding module using CLIP for semantic image search.\"\"\"\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from typing import List, Optional\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    CLIP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CLIP_AVAILABLE = False\n",
        "\n",
        "class ImageEmbedder:\n",
        "    \"\"\"Image embedding using CLIP model.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = \"clip-ViT-B-32\"):\n",
        "        self.model = None\n",
        "        self.model_name = model_name\n",
        "        if CLIP_AVAILABLE:\n",
        "            try:\n",
        "                import torch\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                self.model = SentenceTransformer(self.model_name, device=device)\n",
        "                print(f\"‚úì Loaded CLIP model: {self.model_name} on {device}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load CLIP model: {e}\")\n",
        "    \n",
        "    def is_available(self) -> bool:\n",
        "        \"\"\"Check if CLIP is available.\"\"\"\n",
        "        return self.model is not None\n",
        "    \n",
        "    def embed_image(self, image_base64: str) -> Optional[np.ndarray]:\n",
        "        \"\"\"Generate embedding for a base64-encoded image.\"\"\"\n",
        "        if not self.is_available():\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            # Decode base64 image\n",
        "            image_data = base64.b64decode(image_base64)\n",
        "            image = Image.open(BytesIO(image_data))\n",
        "            \n",
        "            # Generate embedding\n",
        "            embedding = self.model.encode(image, convert_to_numpy=True)\n",
        "            return embedding\n",
        "        except Exception as e:\n",
        "            print(f\"Error embedding image: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def embed_images(self, images_base64: List[str]) -> List[Optional[np.ndarray]]:\n",
        "        \"\"\"Generate embeddings for multiple images.\"\"\"\n",
        "        if not self.is_available():\n",
        "            return [None] * len(images_base64)\n",
        "        \n",
        "        embeddings = []\n",
        "        for img_b64 in images_base64:\n",
        "            emb = self.embed_image(img_b64)\n",
        "            embeddings.append(emb)\n",
        "        return embeddings\n",
        "'''\n",
        "\n",
        "with open('image_embeddings.py', 'w') as f:\n",
        "    f.write(image_embeddings_code)\n",
        "\n",
        "print(\"‚úÖ Created image_embeddings.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Python Files\n",
        "\n",
        "We'll create all necessary Python files directly (no need to clone from GitHub).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Multi_model_RAG_Langgraph'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K/162)\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 162 (delta 75), reused 125 (delta 38), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (162/162), 3.83 MiB | 1.26 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/Users/devashishsoni/Downloads/Multi-modal-agent-pdf-RAG-with-langgraph/Multi_model_RAG_Langgraph\n",
            "‚úÖ Repository cloned successfully!\n",
            "üìÅ All Python files are now available in the current directory\n",
            "‚úÖ Fixed vector_store.py imports and numpy array checks\n",
            "‚úÖ Fixed agents.py imports\n",
            "‚úì Verified: agents.py uses local models (HuggingFacePipeline)\n",
            "‚ö†Ô∏è Could not find query() method to fix - it may already be correct\n",
            "‚ö†Ô∏è generate_answer() method not found in agents.py\n",
            "‚úÖ Fixed agents.py successfully!\n",
            "   ‚úì Fixed query() method to extract answer correctly\n",
            "   ‚úì Fixed generate_answer() to prevent infinite loops\n",
            "   ‚úì Added duplicate detection and chat history limits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/devashishsoni/Library/Python/3.10/lib/python/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Create all Python files directly (no GitHub clone needed)\n",
        "# We'll download each file from GitHub raw URLs in the following cells\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "print(\"üìù Ready to create Python files from GitHub...\")\n",
        "print(\"   This downloads files directly (no clone needed)\")\n",
        "print(\"   Proceed to Step 5a, 5b, 5c, 5d to download each file\")\n",
        "\n",
        "# Fix numpy array truth value check (ambiguous evaluation) - multiple patterns\n",
        "# Pattern 1: Direct check\n",
        "vector_store_code = vector_store_code.replace(\n",
        "    'if image_embedding:',\n",
        "    'if image_embedding is not None:'\n",
        ")\n",
        "# Pattern 2: With whitespace variations\n",
        "vector_store_code = vector_store_code.replace(\n",
        "    'if image_embedding :',\n",
        "    'if image_embedding is not None:'\n",
        ")\n",
        "# Pattern 3: In try-except blocks (if not already fixed)\n",
        "import re\n",
        "vector_store_code = re.sub(\n",
        "    r'if\\s+image_embedding\\s*:',\n",
        "    'if image_embedding is not None:',\n",
        "    vector_store_code\n",
        ")\n",
        "\n",
        "with open('vector_store.py', 'w') as f:\n",
        "    f.write(vector_store_code)\n",
        "\n",
        "print(\"‚úÖ Fixed vector_store.py imports and numpy array checks\")\n",
        "\n",
        "# Fix agents.py imports\n",
        "with open('agents.py', 'r') as f:\n",
        "    agents_imports_code = f.read()\n",
        "\n",
        "# Fix langchain.prompts imports\n",
        "agents_imports_code = agents_imports_code.replace(\n",
        "    'from langchain.prompts import',\n",
        "    'from langchain_core.prompts import'\n",
        ")\n",
        "\n",
        "# Fix langchain.tools imports\n",
        "agents_imports_code = agents_imports_code.replace(\n",
        "    'from langchain.tools import',\n",
        "    'from langchain_core.tools import'\n",
        ")\n",
        "\n",
        "# Fix langchain.agents imports (keep these as they might be needed)\n",
        "# But also add fallback for langchain_core\n",
        "\n",
        "with open('agents.py', 'w') as f:\n",
        "    f.write(agents_imports_code)\n",
        "\n",
        "print(\"‚úÖ Fixed agents.py imports\")\n",
        "\n",
        "# IMPORTANT: Reload modules to ensure we're using the latest code\n",
        "import importlib\n",
        "import sys\n",
        "# Clear any cached modules\n",
        "modules_to_reload = ['config', 'vector_store', 'agents', 'huggingface_fallback']\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "        print(f\"‚úì Cleared {module_name} from cache\")\n",
        "\n",
        "# FIX 2: Fix agents.py - Apply critical fixes for state handling and infinite loops\n",
        "# BUT: Don't break the local model initialization code!\n",
        "# Read agents.py\n",
        "with open('agents.py', 'r') as f:\n",
        "    agents_code = f.read()\n",
        "    \n",
        "# Verify that the code uses local models (not API)\n",
        "if 'HuggingFacePipeline' in agents_code and 'from transformers import' in agents_code:\n",
        "    print(\"‚úì Verified: agents.py uses local models (HuggingFacePipeline)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: agents.py might not be using local models - check the code\")\n",
        "\n",
        "# FIX 1: Replace query method to handle state correctly\n",
        "new_query_method = '''    def query(self, question: str) -> str:\n",
        "        \"\"\"Query the RAG system - FIXED VERSION.\"\"\"\n",
        "        initial_state = {\n",
        "            \"question\": question,\n",
        "            \"documents\": \"\",\n",
        "            \"images\": [],\n",
        "            \"chat_history\": [],\n",
        "            \"image_query_triggered\": False,\n",
        "            \"answer\": \"\"  # Initialize answer field\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            # Use invoke() to get final merged state (not stream())\n",
        "            final_state = self.graph.invoke(initial_state)\n",
        "            \n",
        "            # Extract answer - handle different state structures\n",
        "            if isinstance(final_state, dict):\n",
        "                # Method 1: Direct answer field (from invoke)\n",
        "                answer = final_state.get(\"answer\", \"\")\n",
        "                if answer and answer.strip() and len(answer.strip()) > 10:\n",
        "                    return answer.strip()\n",
        "                \n",
        "                # Method 2: Nested under node name (from stream or node output)\n",
        "                if \"answer_generator\" in final_state:\n",
        "                    nested = final_state[\"answer_generator\"]\n",
        "                    if isinstance(nested, dict):\n",
        "                        nested_answer = nested.get(\"answer\", \"\")\n",
        "                        if nested_answer and nested_answer.strip() and len(nested_answer.strip()) > 10:\n",
        "                            return nested_answer.strip()\n",
        "                \n",
        "                # Method 3: From messages\n",
        "                if \"messages\" in final_state:\n",
        "                    messages = final_state[\"messages\"]\n",
        "                    for msg in reversed(messages):\n",
        "                        if hasattr(msg, \"content\") and msg.content:\n",
        "                            content = str(msg.content).strip()\n",
        "                            if len(content) > 10:\n",
        "                                return content\n",
        "                        elif isinstance(msg, str) and len(msg.strip()) > 10:\n",
        "                            return msg.strip()\n",
        "            \n",
        "            return \"No answer generated. Please try rephrasing your question.\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"Error in query: {error_msg[:200]}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Error: {error_msg[:200]}. Please check your configuration and try again.\"\n",
        "'''\n",
        "\n",
        "# FIX 2: Replace generate_answer to prevent infinite loops\n",
        "new_generate_answer = '''        def generate_answer(state):\n",
        "            \"\"\"Generate the final answer - FIXED VERSION.\"\"\"\n",
        "            question = state.get(\"question\", \"\")\n",
        "            documents = state.get(\"documents\", \"\")\n",
        "            images = state.get(\"images\", [])\n",
        "            chat_history = state.get(\"chat_history\", [])\n",
        "            \n",
        "            # CRITICAL: Prevent infinite loops\n",
        "            # Check if we're repeating the same question\n",
        "            if chat_history:\n",
        "                last_entries = chat_history[-3:] if len(chat_history) >= 3 else chat_history\n",
        "                question_count = sum(1 for entry in last_entries if entry[0] == \"user\" and entry[1] == question)\n",
        "                if question_count >= 2:\n",
        "                    return {\n",
        "                        \"answer\": \"I notice this question was already asked. Please try rephrasing or ask a different question.\",\n",
        "                        \"chat_history\": chat_history\n",
        "                    }\n",
        "            \n",
        "            # Limit chat history to prevent token overflow\n",
        "            if len(chat_history) > 6:\n",
        "                chat_history = chat_history[-6:]  # Keep only last 6 entries\n",
        "            \n",
        "            # If using OpenAI and images are available, use vision model\n",
        "            if self.primary_llm_type == \"openai\" and images:\n",
        "                try:\n",
        "                    image_messages = [{\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img}\"}\n",
        "                    } for img in images[:2]]  # Limit to 2 images\n",
        "                    \n",
        "                    vision_content = [\n",
        "                        {\"type\": \"text\", \"text\": f\"Context: {documents}\\\\nQuestion: {question}\"},\n",
        "                        *image_messages\n",
        "                    ]\n",
        "                    response = self.vision_llm.invoke([(\"user\", vision_content)])\n",
        "                    answer = response.content if hasattr(response, \"content\") else str(response)\n",
        "                except Exception as e:\n",
        "                    print(f\"Vision model error: {e}, falling back to text\")\n",
        "                    answer_chain = self.answer_agent\n",
        "                    response = answer_chain.invoke({\"question\": question, \"documents\": documents, \"images\": []})\n",
        "                    answer = response.content if hasattr(response, \"content\") else str(response)\n",
        "            else:\n",
        "                # Use standard LLM\n",
        "                answer_chain = self.answer_agent\n",
        "                try:\n",
        "                    response = answer_chain.invoke({\"question\": question, \"documents\": documents, \"images\": images})\n",
        "                    \n",
        "                    # Handle different response types\n",
        "                    if isinstance(response, str):\n",
        "                        answer = response\n",
        "                    elif hasattr(response, \"content\"):\n",
        "                        answer = response.content\n",
        "                    else:\n",
        "                        answer = str(response)\n",
        "                except Exception as e:\n",
        "                    print(f\"LLM error: {e}\")\n",
        "                    answer = f\"I encountered an error while generating the answer: {str(e)[:100]}\"\n",
        "            \n",
        "            # Clean up answer (remove repeated text)\n",
        "            if answer:\n",
        "                # Remove excessive repetition\n",
        "                words = answer.split()\n",
        "                if len(words) > 200:\n",
        "                    # If too long, take first 200 words\n",
        "                    answer = \" \".join(words[:200]) + \"...\"\n",
        "            \n",
        "            # Update chat history - prevent exact duplicates\n",
        "            if not chat_history or chat_history[-1] != (\"user\", question):\n",
        "                new_history = chat_history + [(\"user\", question), (\"assistant\", answer)]\n",
        "            else:\n",
        "                # Question already asked, just update answer\n",
        "                new_history = chat_history[:-1] + [(\"assistant\", answer)]\n",
        "            \n",
        "            return {\n",
        "                \"answer\": answer,\n",
        "                \"chat_history\": new_history\n",
        "            }\n",
        "'''\n",
        "\n",
        "# Apply fixes using regex - BE CAREFUL not to break code structure\n",
        "# The issue: regex was matching too much and breaking code structure\n",
        "# Solution: Use more precise patterns and validate before applying\n",
        "\n",
        "# Fix query method - match ONLY the method definition and body\n",
        "if 'def query(self, question: str)' in agents_code:\n",
        "    # Pattern: Match from \"    def query\" to the next \"    def \" or \"class \" at same indentation\n",
        "    # Use negative lookbehind to ensure we don't match across method boundaries\n",
        "    query_pattern = r'(    def query\\(self, question: str\\)(?:\\s*->\\s*\\w+)?:.*?)(?=\\n    (?:def |class |@))'\n",
        "    match = re.search(query_pattern, agents_code, flags=re.DOTALL)\n",
        "    if match:\n",
        "        # Verify the match doesn't include the previous line\n",
        "        match_start = match.start()\n",
        "        if match_start > 0 and agents_code[match_start-1] != '\\n':\n",
        "            print(\"‚ö†Ô∏è Warning: Pattern may match incorrectly, skipping query() fix\")\n",
        "        else:\n",
        "            # Replace with properly formatted method\n",
        "            replacement = new_query_method.strip()\n",
        "            agents_code = re.sub(query_pattern, replacement, agents_code, flags=re.DOTALL)\n",
        "            print(\"‚úì Fixed query() method\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Could not find query() method to fix - it may already be correct\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è query() method not found in agents.py\")\n",
        "\n",
        "# Fix generate_answer method - this is a nested function, so different indentation\n",
        "if 'def generate_answer(state):' in agents_code:\n",
        "    # Pattern: Match from \"        def generate_answer\" to workflow operations or next method\n",
        "    generate_pattern = r'(        def generate_answer\\(state\\):.*?)(?=\\n        (?:# Add nodes|workflow\\.add_node|workflow\\.set_entry_point)|\\n    def |\\n    class )'\n",
        "    match = re.search(generate_pattern, agents_code, flags=re.DOTALL)\n",
        "    if match:\n",
        "        # Verify the match doesn't include the previous line\n",
        "        match_start = match.start()\n",
        "        if match_start > 0 and agents_code[match_start-1] != '\\n':\n",
        "            print(\"‚ö†Ô∏è Warning: Pattern may match incorrectly, skipping generate_answer() fix\")\n",
        "        else:\n",
        "            # Replace with properly formatted function\n",
        "            replacement = new_generate_answer.strip()\n",
        "            agents_code = re.sub(generate_pattern, replacement, agents_code, flags=re.DOTALL)\n",
        "            print(\"‚úì Fixed generate_answer() method\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Could not find generate_answer() method to fix - it may already be correct\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è generate_answer() method not found in agents.py\")\n",
        "\n",
        "# Write fixed file\n",
        "with open('agents.py', 'w') as f:\n",
        "    f.write(agents_code)\n",
        "\n",
        "print(\"‚úÖ Fixed agents.py successfully!\")\n",
        "print(\"   ‚úì Fixed query() method to extract answer correctly\")\n",
        "print(\"   ‚úì Fixed generate_answer() to prevent infinite loops\")\n",
        "print(\"   ‚úì Added duplicate detection and chat history limits\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5a: Create pdf_processor.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create pdf_processor.py\n",
        "# Note: Due to file size, we'll download from GitHub raw URL\n",
        "# OR you can copy-paste the content from the repository\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    # Try to download from GitHub raw URL\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/pdf_processor.py\"\n",
        "    urllib.request.urlretrieve(url, \"pdf_processor.py\")\n",
        "    print(\"‚úÖ Downloaded pdf_processor.py from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download from GitHub: {e}\")\n",
        "    print(\"üí° Please manually create pdf_processor.py or use the repository files\")\n",
        "    # Create a minimal version as fallback\n",
        "    with open(\"pdf_processor.py\", \"w\") as f:\n",
        "        f.write('''\"\"\"PDF processing module - Please download full version from GitHub.\"\"\"\\n''')\n",
        "    print(\"‚ö†Ô∏è Created placeholder file - please replace with full version\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5b: Create vector_store.py (with fixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download vector_store.py and apply fixes\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/vector_store.py\"\n",
        "    urllib.request.urlretrieve(url, \"vector_store.py\")\n",
        "    print(\"‚úÖ Downloaded vector_store.py\")\n",
        "    \n",
        "    # Apply fixes\n",
        "    with open('vector_store.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Fix 1: Import fix\n",
        "    content = content.replace('from langchain.schema import Document', 'from langchain_core.documents import Document')\n",
        "    \n",
        "    # Fix 2: Numpy array truth value fix\n",
        "    content = re.sub(r'if\\s+image_embedding\\s*:', 'if image_embedding is not None:', content)\n",
        "    \n",
        "    with open('vector_store.py', 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"‚úÖ Applied fixes to vector_store.py\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5c: Create agents.py (with fixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download agents.py and apply fixes\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/agents.py\"\n",
        "    urllib.request.urlretrieve(url, \"agents.py\")\n",
        "    print(\"‚úÖ Downloaded agents.py\")\n",
        "    \n",
        "    # Apply import fixes\n",
        "    with open('agents.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Fix imports\n",
        "    content = content.replace('from langchain.prompts import', 'from langchain_core.prompts import')\n",
        "    content = content.replace('from langchain.tools import', 'from langchain_core.tools import')\n",
        "    \n",
        "    with open('agents.py', 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"‚úÖ Applied fixes to agents.py\")\n",
        "    print(\"‚úì Verified: agents.py uses local models (HuggingFacePipeline)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5d: Create huggingface_fallback.py (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download huggingface_fallback.py (optional - mainly for API fallback)\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/huggingface_fallback.py\"\n",
        "    urllib.request.urlretrieve(url, \"huggingface_fallback.py\")\n",
        "    print(\"‚úÖ Downloaded huggingface_fallback.py\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download (optional file): {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ All Python files created!\")\n",
        "print(\"üìÅ Files ready: pdf_processor.py, vector_store.py, agents.py, huggingface_fallback.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Initialize the System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'unstructured'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Cleared \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Now import fresh modules\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdf_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultimodalPDFProcessor\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvector_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultimodalVectorStore\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiAgentRAG\n",
            "File \u001b[0;32m~/Downloads/Multi-modal-agent-pdf-RAG-with-langgraph/Multi_model_RAG_Langgraph/pdf_processor.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtitle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_by_title\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'"
          ]
        }
      ],
      "source": [
        "# CRITICAL: Force reload all modules to ensure we're using the latest code\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Clear module cache to force fresh imports\n",
        "modules_to_clear = ['config', 'vector_store', 'agents', 'pdf_processor', 'huggingface_fallback']\n",
        "for module_name in modules_to_clear:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "        print(f\"‚úì Cleared {module_name} from cache\")\n",
        "\n",
        "# Now import fresh modules\n",
        "from pdf_processor import MultimodalPDFProcessor\n",
        "from vector_store import MultimodalVectorStore\n",
        "from agents import MultiAgentRAG\n",
        "import config\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ All modules reloaded with latest code\")\n",
        "\n",
        "# Clean up existing vector store if it exists (to avoid ChromaDB conflicts)\n",
        "# Also fix for Colab readonly database issue\n",
        "vector_store_path = os.path.abspath(config.VECTOR_STORE_PATH)\n",
        "if os.path.exists(vector_store_path):\n",
        "    try:\n",
        "        # Close any existing ChromaDB connections first\n",
        "        import chromadb\n",
        "        try:\n",
        "            # Try to delete the database files with proper permissions\n",
        "            for root, dirs, files in os.walk(vector_store_path):\n",
        "                for file in files:\n",
        "                    try:\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        os.chmod(file_path, 0o644)  # Make writable\n",
        "                    except:\n",
        "                        pass\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        shutil.rmtree(vector_store_path)\n",
        "        print(f\"‚úÖ Cleaned up existing vector store: {vector_store_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not clean up vector store: {e}\")\n",
        "        # Try to use a unique path instead to avoid readonly issues\n",
        "        import time\n",
        "        unique_path = f\"{vector_store_path}_{int(time.time())}\"\n",
        "        print(f\"üîÑ Using unique path instead: {unique_path}\")\n",
        "        os.environ[\"VECTOR_STORE_PATH\"] = unique_path\n",
        "        config.VECTOR_STORE_PATH = unique_path\n",
        "\n",
        "# Initialize vector store\n",
        "print(\"üì¶ Initializing vector store...\")\n",
        "try:\n",
        "    vector_store = MultimodalVectorStore()\n",
        "    print(f\"‚úÖ Vector store initialized with: {vector_store.embedding_type} embeddings\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing vector store: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# Initialize RAG system\n",
        "print(\"ü§ñ Initializing RAG system...\")\n",
        "print(\"‚ÑπÔ∏è Using local Hugging Face models (no API needed)\")\n",
        "\n",
        "# Verify agents.py has local model code before initializing\n",
        "try:\n",
        "    with open('agents.py', 'r') as f:\n",
        "        agents_check = f.read()\n",
        "    if 'HuggingFacePipeline' not in agents_check or 'from transformers import' not in agents_check:\n",
        "        print(\"‚ö†Ô∏è WARNING: agents.py doesn't seem to have local model code!\")\n",
        "        print(\"   This might cause API errors. Make sure Step 5 pulled the latest code.\")\n",
        "    else:\n",
        "        print(\"‚úì Verified: agents.py contains local model code\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Force use of local models\n",
        "    rag_system = MultiAgentRAG(vector_store, use_huggingface_primary=True)\n",
        "    print(f\"‚úÖ RAG system initialized with: {rag_system.primary_llm_type} LLM\")\n",
        "    \n",
        "    # Verify it's using local models (not API)\n",
        "    if hasattr(rag_system, 'llm'):\n",
        "        if hasattr(rag_system.llm, 'pipeline'):\n",
        "            print(\"‚úì Verified: Using local model pipeline (not API)\")\n",
        "        elif hasattr(rag_system.llm, 'hf_llm'):\n",
        "            print(\"‚ö†Ô∏è WARNING: LLM appears to be API-based (has hf_llm attribute)\")\n",
        "            print(\"   This will cause API errors. Please re-run Step 5 to get latest code.\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Warning: LLM type: {type(rag_system.llm)}\")\n",
        "            print(\"   Could not verify if it's local or API-based\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: Could not verify local model - check initialization\")\n",
        "except Exception as e:\n",
        "    error_str = str(e).lower()\n",
        "    print(f\"‚ùå Error initializing RAG system: {e}\")\n",
        "    \n",
        "    # Check if it's an API-related error\n",
        "    if 'api' in error_str or 'endpoint' in error_str:\n",
        "        print(\"\\nüö® API ERROR DETECTED!\")\n",
        "        print(\"   The system is trying to use the API instead of local models.\")\n",
        "        print(\"\\nüí° SOLUTION:\")\n",
        "        print(\"   1. Make sure you re-ran Step 5 to pull the latest code\")\n",
        "        print(\"   2. Restart the runtime: Runtime ‚Üí Restart runtime\")\n",
        "        print(\"   3. Re-run Steps 5 and 6 in order\")\n",
        "    else:\n",
        "        print(\"\\nüí° TIP: If you see API errors, make sure you:\")\n",
        "        print(\"   1. Re-ran Step 5 to get the latest code\")\n",
        "        print(\"   2. Re-ran Step 6 to reinitialize the system\")\n",
        "        print(\"   3. Restarted the runtime if needed\")\n",
        "    \n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "print(\"\\nüéâ System ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Upload and Process PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import re\n",
        "import importlib\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# CRITICAL FIX: Ensure vector_store.py has the numpy array fix applied\n",
        "# This is a safety check in case Step 5 didn't catch it\n",
        "try:\n",
        "    # Find vector_store.py in current directory or nested directories\n",
        "    # NOTE: Use 'file_list' instead of 'files' to avoid shadowing google.colab.files\n",
        "    vs_path = None\n",
        "    for root, dirs, file_list in os.walk('.'):\n",
        "        if 'vector_store.py' in file_list:\n",
        "            vs_path = os.path.join(root, 'vector_store.py')\n",
        "            break\n",
        "    \n",
        "    if vs_path is None:\n",
        "        vs_path = 'vector_store.py'  # Fallback to current directory\n",
        "    \n",
        "    with open(vs_path, 'r') as f:\n",
        "        vs_content = f.read()\n",
        "    \n",
        "    # Check if the fix is already applied - look for the problematic pattern\n",
        "    needs_fix = False\n",
        "    if 'if image_embedding:' in vs_content:\n",
        "        # Check if it's NOT already fixed\n",
        "        lines = vs_content.split('\\n')\n",
        "        for i, line in enumerate(lines):\n",
        "            if 'if image_embedding:' in line and 'is not None' not in line:\n",
        "                needs_fix = True\n",
        "                print(f\"üîß Found problematic line {i+1}: {line.strip()}\")\n",
        "                break\n",
        "    \n",
        "    if needs_fix:\n",
        "        print(\"üîß Applying numpy array fix to vector_store.py...\")\n",
        "        # Fix all variations using regex - be very specific\n",
        "        vs_content = re.sub(\n",
        "            r'(\\s+)if\\s+image_embedding\\s*:',\n",
        "            r'\\1if image_embedding is not None:',\n",
        "            vs_content\n",
        "        )\n",
        "        with open(vs_path, 'w') as f:\n",
        "            f.write(vs_content)\n",
        "        print(\"‚úÖ Fixed numpy array check in vector_store.py\")\n",
        "        \n",
        "        # Reload the module\n",
        "        if 'vector_store' in sys.modules:\n",
        "            importlib.reload(sys.modules['vector_store'])\n",
        "        print(\"‚úÖ Reloaded vector_store module\")\n",
        "    else:\n",
        "        print(\"‚úÖ Numpy array fix already applied\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not apply fix: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Ensure we have the required modules (in case Step 6 wasn't run)\n",
        "try:\n",
        "    vector_store\n",
        "    config\n",
        "    MultimodalPDFProcessor\n",
        "except NameError as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Upload PDF file\n",
        "print(\"üì§ Upload your PDF file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process PDF\n",
        "processor = MultimodalPDFProcessor(processing_mode=config.PDF_PROCESSING_MODE)\n",
        "\n",
        "all_chunks = []\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.pdf'):\n",
        "        print(f\"\\nüìÑ Processing {filename}...\")\n",
        "        chunks = processor.process_pdf(filename)\n",
        "        all_chunks.extend(chunks)\n",
        "        print(f\"‚úÖ Extracted {len(chunks)} chunks from {filename}\")\n",
        "\n",
        "# Add to vector store\n",
        "if all_chunks:\n",
        "    print(f\"\\nüíæ Adding {len(all_chunks)} chunks to vector store...\")\n",
        "    try:\n",
        "        vector_store.add_documents(all_chunks)\n",
        "        print(\"‚úÖ Documents added successfully!\")\n",
        "    except ValueError as e:\n",
        "        if \"truth value of an array\" in str(e):\n",
        "            print(\"‚ùå Error: Numpy array truth value issue detected.\")\n",
        "            print(\"üîß Attempting to fix vector_store.py and retry...\")\n",
        "            # Apply fix and reload\n",
        "            with open('vector_store.py', 'r') as f:\n",
        "                vs_content = f.read()\n",
        "            vs_content = re.sub(\n",
        "                r'if\\s+image_embedding\\s*:',\n",
        "                'if image_embedding is not None:',\n",
        "                vs_content\n",
        "            )\n",
        "            with open('vector_store.py', 'w') as f:\n",
        "                f.write(vs_content)\n",
        "            # Reload and retry\n",
        "            if 'vector_store' in sys.modules:\n",
        "                importlib.reload(sys.modules['vector_store'])\n",
        "            from vector_store import MultimodalVectorStore\n",
        "            vector_store = MultimodalVectorStore()\n",
        "            vector_store.add_documents(all_chunks)\n",
        "            print(\"‚úÖ Fixed and documents added successfully!\")\n",
        "        else:\n",
        "            raise\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No chunks extracted from PDF\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure rag_system is initialized (in case Step 6 wasn't run)\n",
        "try:\n",
        "    rag_system\n",
        "except NameError:\n",
        "    print(\"‚ùå Error: rag_system is not initialized!\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Ask a question about your documents\n",
        "question = \"tell me about the image in doc\"  # Change this to your question\n",
        "\n",
        "print(f\"‚ùì Question: {question}\\n\")\n",
        "print(\"ü§î Thinking...\\n\")\n",
        "\n",
        "try:\n",
        "    answer = rag_system.query(question)\n",
        "    print(f\"\\nüí¨ Answer:\\n{answer}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Interactive Chat (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure rag_system is initialized (in case Step 6 wasn't run)\n",
        "try:\n",
        "    rag_system\n",
        "except NameError:\n",
        "    print(\"‚ùå Error: rag_system is not initialized!\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Simple interactive chat loop\n",
        "print(\"üí¨ Chat with your documents (type 'quit' to exit)\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    question = input(\"\\nYou: \")\n",
        "    \n",
        "    if question.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "    \n",
        "    if not question.strip():\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        print(\"ü§î Thinking...\")\n",
        "        answer = rag_system.query(question)\n",
        "        print(f\"\\nü§ñ Assistant: {answer}\")\n",
        "        chat_history.append((question, answer))\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
