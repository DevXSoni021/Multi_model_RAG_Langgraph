{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö Multi-modal PDF RAG with LangGraph - Complete Google Colab Guide\n",
        "\n",
        "**Run this on GPU for best performance!**\n",
        "\n",
        "This notebook provides a complete multi-modal RAG system that can:\n",
        "- Process PDFs with text, images, and tables\n",
        "- Perform semantic search on both text and images  \n",
        "- Answer questions using a multi-agent system\n",
        "- Use Hugging Face models (free, no OpenAI required)\n",
        "\n",
        "## ‚öôÔ∏è Setup Steps:\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or better)\n",
        "2. **Hugging Face API key (OPTIONAL)**: https://huggingface.co/settings/tokens\n",
        "   - Note: We use **local models** by default, so API key is not required!\n",
        "   - Only needed if you want to use Hugging Face API for some features\n",
        "3. **Run all cells in order** (Step 1 ‚Üí Step 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install All Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 0.1.0 not found\n",
            "zsh:1: no matches found: unstructured[pdf]\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "zsh:1: 2.7.4, not found\n",
            "zsh:1: command not found: apt-get\n",
            "zsh:1: command not found: apt-get\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "%pip install -q langchain>=0.1.0 langchain-openai>=0.0.2 langchain-community>=0.0.10 langgraph>=0.0.20\n",
        "%pip install -q \"unstructured[pdf]\" pypdf pdf2image Pillow\n",
        "%pip install -q chromadb faiss-cpu\n",
        "%pip install -q sentence-transformers torch torchvision\n",
        "%pip install -q duckduckgo-search tavily-python\n",
        "%pip install -q python-dotenv requests opencv-python\n",
        "%pip install -q \"numpy==1.24.3\" \"pydantic>=2.7.4,<3.0.0\"\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq poppler-utils tesseract-ocr\n",
        "\n",
        "# Verify critical packages are installed\n",
        "import importlib\n",
        "critical_packages = ['unstructured', 'chromadb', 'sentence_transformers', 'langchain', 'langgraph']\n",
        "missing = []\n",
        "for pkg in critical_packages:\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "    except ImportError:\n",
        "        missing.append(pkg)\n",
        "\n",
        "if missing:\n",
        "    print(f\"‚ö†Ô∏è Missing packages: {missing}\")\n",
        "    print(\"Attempting to install missing packages...\")\n",
        "    for pkg in missing:\n",
        "        if pkg == 'unstructured':\n",
        "            %pip install -q \"unstructured[pdf]\"\n",
        "        else:\n",
        "            %pip install -q {pkg}\n",
        "    print(\"‚úÖ Re-installed missing packages\")\n",
        "else:\n",
        "    print(\"‚úÖ All critical packages verified!\")\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Set Your API Keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ API keys configured!\n",
            "‚úì Hugging Face API key set: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ‚ö†Ô∏è REPLACE WITH YOUR ACTUAL API KEYS ‚ö†Ô∏è\n",
        "# Note: Hugging Face API key is OPTIONAL - we use local models (no API needed)\n",
        "# Only needed if you want to use Hugging Face API for some features\n",
        "HUGGINGFACE_API_KEY = \"YOUR_HUGGINGFACE_API_KEY_HERE\"  # Optional - Get from https://huggingface.co/settings/tokens\n",
        "TAVILY_API_KEY = \"YOUR_TAVILY_API_KEY_HERE\"  # Optional - For web search\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
        "os.environ[\"USE_HUGGINGFACE_PRIMARY\"] = \"true\"\n",
        "os.environ[\"USE_OPENAI_EMBEDDINGS\"] = \"false\"\n",
        "os.environ[\"USE_OPENAI_FALLBACK\"] = \"false\"\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "\n",
        "print(\"‚úÖ API keys configured!\")\n",
        "print(f\"‚úì Hugging Face API key set: {bool(HUGGINGFACE_API_KEY and HUGGINGFACE_API_KEY != 'YOUR_HUGGINGFACE_API_KEY_HERE')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Configuration File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created config.py\n"
          ]
        }
      ],
      "source": [
        "# Create config.py\n",
        "config_code = '''\"\"\"Configuration settings for the Multi-modal RAG system.\"\"\"\n",
        "import os\n",
        "\n",
        "# API Keys\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\", \"\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
        "\n",
        "# Model Configuration\n",
        "LLM_MODEL = \"gpt-4-1106-preview\"\n",
        "VISION_MODEL = \"gpt-4-vision-preview\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
        "\n",
        "# Hugging Face Configuration\n",
        "HUGGINGFACE_LLM_MODEL = os.getenv(\"HUGGINGFACE_LLM_MODEL\", \"distilgpt2\")  # Use distilgpt2 for faster local loading\n",
        "HUGGINGFACE_MULTIMODAL_MODEL = \"Salesforce/blip-image-captioning-large\"\n",
        "USE_HUGGINGFACE_PRIMARY = os.getenv(\"USE_HUGGINGFACE_PRIMARY\", \"true\").lower() == \"true\"\n",
        "USE_OPENAI_EMBEDDINGS = os.getenv(\"USE_OPENAI_EMBEDDINGS\", \"false\").lower() == \"true\"\n",
        "USE_OPENAI_FALLBACK = os.getenv(\"USE_OPENAI_FALLBACK\", \"false\").lower() == \"true\"\n",
        "\n",
        "# Vector Store Configuration\n",
        "VECTOR_STORE_PATH = os.getenv(\"VECTOR_STORE_PATH\", \"./vector_store\")\n",
        "CHROMA_COLLECTION_NAME = \"multimodal_pdf_rag\"\n",
        "MAX_RETRIEVAL_DOCS = 3\n",
        "MAX_IMAGES_PER_QUERY = 2\n",
        "\n",
        "# PDF Processing Configuration\n",
        "PDF_PROCESSING_MODE = \"hi_res\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "# Agent Configuration\n",
        "MAX_ITERATIONS = 30\n",
        "TEMPERATURE = 0.0\n",
        "\n",
        "# Rate Limit Configuration\n",
        "MAX_RETRIES = 3\n",
        "RETRY_DELAY_SECONDS = 2\n",
        "'''\n",
        "\n",
        "with open('config.py', 'w') as f:\n",
        "    f.write(config_code)\n",
        "\n",
        "print(\"‚úÖ Created config.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Image Embeddings Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created image_embeddings.py\n"
          ]
        }
      ],
      "source": [
        "# Create image_embeddings.py\n",
        "image_embeddings_code = '''\"\"\"Image embedding module using CLIP for semantic image search.\"\"\"\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from typing import List, Optional\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    CLIP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CLIP_AVAILABLE = False\n",
        "\n",
        "class ImageEmbedder:\n",
        "    \"\"\"Image embedding using CLIP model.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = \"clip-ViT-B-32\"):\n",
        "        self.model = None\n",
        "        self.model_name = model_name\n",
        "        if CLIP_AVAILABLE:\n",
        "            try:\n",
        "                import torch\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                self.model = SentenceTransformer(self.model_name, device=device)\n",
        "                print(f\"‚úì Loaded CLIP model: {self.model_name} on {device}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load CLIP model: {e}\")\n",
        "    \n",
        "    def is_available(self) -> bool:\n",
        "        \"\"\"Check if CLIP is available.\"\"\"\n",
        "        return self.model is not None\n",
        "    \n",
        "    def embed_image(self, image_base64: str) -> Optional[np.ndarray]:\n",
        "        \"\"\"Generate embedding for a base64-encoded image.\"\"\"\n",
        "        if not self.is_available():\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            # Decode base64 image\n",
        "            image_data = base64.b64decode(image_base64)\n",
        "            image = Image.open(BytesIO(image_data))\n",
        "            \n",
        "            # Generate embedding\n",
        "            embedding = self.model.encode(image, convert_to_numpy=True)\n",
        "            return embedding\n",
        "        except Exception as e:\n",
        "            print(f\"Error embedding image: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def embed_images(self, images_base64: List[str]) -> List[Optional[np.ndarray]]:\n",
        "        \"\"\"Generate embeddings for multiple images.\"\"\"\n",
        "        if not self.is_available():\n",
        "            return [None] * len(images_base64)\n",
        "        \n",
        "        embeddings = []\n",
        "        for img_b64 in images_base64:\n",
        "            emb = self.embed_image(img_b64)\n",
        "            embeddings.append(emb)\n",
        "        return embeddings\n",
        "'''\n",
        "\n",
        "with open('image_embeddings.py', 'w') as f:\n",
        "    f.write(image_embeddings_code)\n",
        "\n",
        "print(\"‚úÖ Created image_embeddings.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Python Files\n",
        "\n",
        "We'll create all necessary Python files directly (no need to clone from GitHub).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Ready to create Python files from GitHub...\n",
            "   This downloads files directly (no clone needed)\n",
            "   Proceed to Step 5a, 5b, 5c, 5d to download each file\n",
            "‚úÖ Fixed vector_store.py imports and numpy array checks\n",
            "‚úÖ Fixed agents.py imports\n",
            "‚úì Verified: agents.py uses local models (HuggingFacePipeline)\n",
            "‚ö†Ô∏è Could not find query() method to fix - it may already be correct\n",
            "‚ö†Ô∏è generate_answer() method not found in agents.py\n",
            "‚úÖ Fixed agents.py successfully!\n",
            "   ‚úì Fixed query() method to extract answer correctly\n",
            "   ‚úì Fixed generate_answer() to prevent infinite loops\n",
            "   ‚úì Added duplicate detection and chat history limits\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Create all Python files directly (no GitHub clone needed)\n",
        "# We'll download each file from GitHub raw URLs in the following cells\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "print(\"üìù Ready to create Python files from GitHub...\")\n",
        "print(\"   This downloads files directly (no clone needed)\")\n",
        "print(\"   Proceed to Step 5a, 5b, 5c, 5d to download each file\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5a: Create pdf_processor.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded pdf_processor.py from GitHub\n"
          ]
        }
      ],
      "source": [
        "# Create pdf_processor.py\n",
        "# Note: Due to file size, we'll download from GitHub raw URL\n",
        "# OR you can copy-paste the content from the repository\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    # Try to download from GitHub raw URL\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/pdf_processor.py\"\n",
        "    urllib.request.urlretrieve(url, \"pdf_processor.py\")\n",
        "    print(\"‚úÖ Downloaded pdf_processor.py from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download from GitHub: {e}\")\n",
        "    print(\"üí° Please manually create pdf_processor.py or use the repository files\")\n",
        "    # Create a minimal version as fallback\n",
        "    with open(\"pdf_processor.py\", \"w\") as f:\n",
        "        f.write('''\"\"\"PDF processing module - Please download full version from GitHub.\"\"\"\\n''')\n",
        "    print(\"‚ö†Ô∏è Created placeholder file - please replace with full version\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5b: Create vector_store.py (with fixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded vector_store.py\n",
            "‚úÖ Applied fixes to vector_store.py\n"
          ]
        }
      ],
      "source": [
        "# Download vector_store.py and apply fixes\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/vector_store.py\"\n",
        "    urllib.request.urlretrieve(url, \"vector_store.py\")\n",
        "    print(\"‚úÖ Downloaded vector_store.py\")\n",
        "    \n",
        "    # Apply fixes\n",
        "    with open('vector_store.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Fix 1: Import fix\n",
        "    content = content.replace('from langchain.schema import Document', 'from langchain_core.documents import Document')\n",
        "    \n",
        "    # Fix 2: Numpy array truth value fix\n",
        "    content = re.sub(r'if\\s+image_embedding\\s*:', 'if image_embedding is not None:', content)\n",
        "    \n",
        "    with open('vector_store.py', 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"‚úÖ Applied fixes to vector_store.py\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5c: Create agents.py (with fixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded agents.py\n",
            "‚úÖ Applied fixes to agents.py\n",
            "‚úì Verified: agents.py uses local models (HuggingFacePipeline)\n"
          ]
        }
      ],
      "source": [
        "# Download agents.py and apply fixes\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/agents.py\"\n",
        "    urllib.request.urlretrieve(url, \"agents.py\")\n",
        "    print(\"‚úÖ Downloaded agents.py\")\n",
        "    \n",
        "    # Apply import fixes\n",
        "    with open('agents.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Fix imports\n",
        "    content = content.replace('from langchain.prompts import', 'from langchain_core.prompts import')\n",
        "    content = content.replace('from langchain.tools import', 'from langchain_core.tools import')\n",
        "    \n",
        "    with open('agents.py', 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"‚úÖ Applied fixes to agents.py\")\n",
        "    print(\"‚úì Verified: agents.py uses local models (HuggingFacePipeline)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5d: Create huggingface_fallback.py (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded huggingface_fallback.py\n",
            "\n",
            "‚úÖ All Python files created!\n",
            "üìÅ Files ready: pdf_processor.py, vector_store.py, agents.py, huggingface_fallback.py\n"
          ]
        }
      ],
      "source": [
        "# Download huggingface_fallback.py (optional - mainly for API fallback)\n",
        "import urllib.request\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/DevXSoni021/Multi_model_RAG_Langgraph/main/huggingface_fallback.py\"\n",
        "    urllib.request.urlretrieve(url, \"huggingface_fallback.py\")\n",
        "    print(\"‚úÖ Downloaded huggingface_fallback.py\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download (optional file): {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ All Python files created!\")\n",
        "print(\"üìÅ Files ready: pdf_processor.py, vector_store.py, agents.py, huggingface_fallback.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Initialize the System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'unstructured'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Cleared \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Now import fresh modules\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdf_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultimodalPDFProcessor\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvector_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultimodalVectorStore\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiAgentRAG\n",
            "File \u001b[0;32m~/Downloads/Multi-modal-agent-pdf-RAG-with-langgraph/Multi_model_RAG_Langgraph/pdf_processor.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtitle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_by_title\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'"
          ]
        }
      ],
      "source": [
        "# CRITICAL: Force reload all modules to ensure we're using the latest code\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Clear module cache to force fresh imports\n",
        "modules_to_clear = ['config', 'vector_store', 'agents', 'pdf_processor', 'huggingface_fallback']\n",
        "for module_name in modules_to_clear:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "        print(f\"‚úì Cleared {module_name} from cache\")\n",
        "\n",
        "# Now import fresh modules\n",
        "from pdf_processor import MultimodalPDFProcessor\n",
        "from vector_store import MultimodalVectorStore\n",
        "from agents import MultiAgentRAG\n",
        "import config\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ All modules reloaded with latest code\")\n",
        "\n",
        "# Clean up existing vector store if it exists (to avoid ChromaDB conflicts)\n",
        "# Also fix for Colab readonly database issue\n",
        "vector_store_path = os.path.abspath(config.VECTOR_STORE_PATH)\n",
        "if os.path.exists(vector_store_path):\n",
        "    try:\n",
        "        # Close any existing ChromaDB connections first\n",
        "        import chromadb\n",
        "        try:\n",
        "            # Try to delete the database files with proper permissions\n",
        "            for root, dirs, files in os.walk(vector_store_path):\n",
        "                for file in files:\n",
        "                    try:\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        os.chmod(file_path, 0o644)  # Make writable\n",
        "                    except:\n",
        "                        pass\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        shutil.rmtree(vector_store_path)\n",
        "        print(f\"‚úÖ Cleaned up existing vector store: {vector_store_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not clean up vector store: {e}\")\n",
        "        # Try to use a unique path instead to avoid readonly issues\n",
        "        import time\n",
        "        unique_path = f\"{vector_store_path}_{int(time.time())}\"\n",
        "        print(f\"üîÑ Using unique path instead: {unique_path}\")\n",
        "        os.environ[\"VECTOR_STORE_PATH\"] = unique_path\n",
        "        config.VECTOR_STORE_PATH = unique_path\n",
        "\n",
        "# Initialize vector store\n",
        "print(\"üì¶ Initializing vector store...\")\n",
        "try:\n",
        "    vector_store = MultimodalVectorStore()\n",
        "    print(f\"‚úÖ Vector store initialized with: {vector_store.embedding_type} embeddings\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing vector store: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# Initialize RAG system\n",
        "print(\"ü§ñ Initializing RAG system...\")\n",
        "print(\"‚ÑπÔ∏è Using local Hugging Face models (no API needed)\")\n",
        "\n",
        "# Verify agents.py has local model code before initializing\n",
        "try:\n",
        "    with open('agents.py', 'r') as f:\n",
        "        agents_check = f.read()\n",
        "    if 'HuggingFacePipeline' not in agents_check or 'from transformers import' not in agents_check:\n",
        "        print(\"‚ö†Ô∏è WARNING: agents.py doesn't seem to have local model code!\")\n",
        "        print(\"   This might cause API errors. Make sure Step 5 pulled the latest code.\")\n",
        "    else:\n",
        "        print(\"‚úì Verified: agents.py contains local model code\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Force use of local models\n",
        "    rag_system = MultiAgentRAG(vector_store, use_huggingface_primary=True)\n",
        "    print(f\"‚úÖ RAG system initialized with: {rag_system.primary_llm_type} LLM\")\n",
        "    \n",
        "    # Verify it's using local models (not API)\n",
        "    if hasattr(rag_system, 'llm'):\n",
        "        if hasattr(rag_system.llm, 'pipeline'):\n",
        "            print(\"‚úì Verified: Using local model pipeline (not API)\")\n",
        "        elif hasattr(rag_system.llm, 'hf_llm'):\n",
        "            print(\"‚ö†Ô∏è WARNING: LLM appears to be API-based (has hf_llm attribute)\")\n",
        "            print(\"   This will cause API errors. Please re-run Step 5 to get latest code.\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Warning: LLM type: {type(rag_system.llm)}\")\n",
        "            print(\"   Could not verify if it's local or API-based\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: Could not verify local model - check initialization\")\n",
        "except Exception as e:\n",
        "    error_str = str(e).lower()\n",
        "    print(f\"‚ùå Error initializing RAG system: {e}\")\n",
        "    \n",
        "    # Check if it's an API-related error\n",
        "    if 'api' in error_str or 'endpoint' in error_str:\n",
        "        print(\"\\nüö® API ERROR DETECTED!\")\n",
        "        print(\"   The system is trying to use the API instead of local models.\")\n",
        "        print(\"\\nüí° SOLUTION:\")\n",
        "        print(\"   1. Make sure you re-ran Step 5 to pull the latest code\")\n",
        "        print(\"   2. Restart the runtime: Runtime ‚Üí Restart runtime\")\n",
        "        print(\"   3. Re-run Steps 5 and 6 in order\")\n",
        "    else:\n",
        "        print(\"\\nüí° TIP: If you see API errors, make sure you:\")\n",
        "        print(\"   1. Re-ran Step 5 to get the latest code\")\n",
        "        print(\"   2. Re-ran Step 6 to reinitialize the system\")\n",
        "        print(\"   3. Restarted the runtime if needed\")\n",
        "    \n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "print(\"\\nüéâ System ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Upload and Process PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import re\n",
        "import importlib\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# CRITICAL FIX: Ensure vector_store.py has the numpy array fix applied\n",
        "# This is a safety check in case Step 5 didn't catch it\n",
        "try:\n",
        "    # Find vector_store.py in current directory or nested directories\n",
        "    # NOTE: Use 'file_list' instead of 'files' to avoid shadowing google.colab.files\n",
        "    vs_path = None\n",
        "    for root, dirs, file_list in os.walk('.'):\n",
        "        if 'vector_store.py' in file_list:\n",
        "            vs_path = os.path.join(root, 'vector_store.py')\n",
        "            break\n",
        "    \n",
        "    if vs_path is None:\n",
        "        vs_path = 'vector_store.py'  # Fallback to current directory\n",
        "    \n",
        "    with open(vs_path, 'r') as f:\n",
        "        vs_content = f.read()\n",
        "    \n",
        "    # Check if the fix is already applied - look for the problematic pattern\n",
        "    needs_fix = False\n",
        "    if 'if image_embedding:' in vs_content:\n",
        "        # Check if it's NOT already fixed\n",
        "        lines = vs_content.split('\\n')\n",
        "        for i, line in enumerate(lines):\n",
        "            if 'if image_embedding:' in line and 'is not None' not in line:\n",
        "                needs_fix = True\n",
        "                print(f\"üîß Found problematic line {i+1}: {line.strip()}\")\n",
        "                break\n",
        "    \n",
        "    if needs_fix:\n",
        "        print(\"üîß Applying numpy array fix to vector_store.py...\")\n",
        "        # Fix all variations using regex - be very specific\n",
        "        vs_content = re.sub(\n",
        "            r'(\\s+)if\\s+image_embedding\\s*:',\n",
        "            r'\\1if image_embedding is not None:',\n",
        "            vs_content\n",
        "        )\n",
        "        with open(vs_path, 'w') as f:\n",
        "            f.write(vs_content)\n",
        "        print(\"‚úÖ Fixed numpy array check in vector_store.py\")\n",
        "        \n",
        "        # Reload the module\n",
        "        if 'vector_store' in sys.modules:\n",
        "            importlib.reload(sys.modules['vector_store'])\n",
        "        print(\"‚úÖ Reloaded vector_store module\")\n",
        "    else:\n",
        "        print(\"‚úÖ Numpy array fix already applied\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not apply fix: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Ensure we have the required modules (in case Step 6 wasn't run)\n",
        "try:\n",
        "    vector_store\n",
        "    config\n",
        "    MultimodalPDFProcessor\n",
        "except NameError as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Upload PDF file\n",
        "print(\"üì§ Upload your PDF file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process PDF\n",
        "processor = MultimodalPDFProcessor(processing_mode=config.PDF_PROCESSING_MODE)\n",
        "\n",
        "all_chunks = []\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.pdf'):\n",
        "        print(f\"\\nüìÑ Processing {filename}...\")\n",
        "        chunks = processor.process_pdf(filename)\n",
        "        all_chunks.extend(chunks)\n",
        "        print(f\"‚úÖ Extracted {len(chunks)} chunks from {filename}\")\n",
        "\n",
        "# Add to vector store\n",
        "if all_chunks:\n",
        "    print(f\"\\nüíæ Adding {len(all_chunks)} chunks to vector store...\")\n",
        "    try:\n",
        "        vector_store.add_documents(all_chunks)\n",
        "        print(\"‚úÖ Documents added successfully!\")\n",
        "    except ValueError as e:\n",
        "        if \"truth value of an array\" in str(e):\n",
        "            print(\"‚ùå Error: Numpy array truth value issue detected.\")\n",
        "            print(\"üîß Attempting to fix vector_store.py and retry...\")\n",
        "            # Apply fix and reload\n",
        "            with open('vector_store.py', 'r') as f:\n",
        "                vs_content = f.read()\n",
        "            vs_content = re.sub(\n",
        "                r'if\\s+image_embedding\\s*:',\n",
        "                'if image_embedding is not None:',\n",
        "                vs_content\n",
        "            )\n",
        "            with open('vector_store.py', 'w') as f:\n",
        "                f.write(vs_content)\n",
        "            # Reload and retry\n",
        "            if 'vector_store' in sys.modules:\n",
        "                importlib.reload(sys.modules['vector_store'])\n",
        "            from vector_store import MultimodalVectorStore\n",
        "            vector_store = MultimodalVectorStore()\n",
        "            vector_store.add_documents(all_chunks)\n",
        "            print(\"‚úÖ Fixed and documents added successfully!\")\n",
        "        else:\n",
        "            raise\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No chunks extracted from PDF\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure rag_system is initialized (in case Step 6 wasn't run)\n",
        "try:\n",
        "    rag_system\n",
        "except NameError:\n",
        "    print(\"‚ùå Error: rag_system is not initialized!\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Ask a question about your documents\n",
        "question = \"tell me about the image in doc\"  # Change this to your question\n",
        "\n",
        "print(f\"‚ùì Question: {question}\\n\")\n",
        "print(\"ü§î Thinking...\\n\")\n",
        "\n",
        "try:\n",
        "    answer = rag_system.query(question)\n",
        "    print(f\"\\nüí¨ Answer:\\n{answer}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Interactive Chat (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure rag_system is initialized (in case Step 6 wasn't run)\n",
        "try:\n",
        "    rag_system\n",
        "except NameError:\n",
        "    print(\"‚ùå Error: rag_system is not initialized!\")\n",
        "    print(\"‚ö†Ô∏è Please run Step 6 first to initialize the system!\")\n",
        "    raise\n",
        "\n",
        "# Simple interactive chat loop\n",
        "print(\"üí¨ Chat with your documents (type 'quit' to exit)\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    question = input(\"\\nYou: \")\n",
        "    \n",
        "    if question.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "    \n",
        "    if not question.strip():\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        print(\"ü§î Thinking...\")\n",
        "        answer = rag_system.query(question)\n",
        "        print(f\"\\nü§ñ Assistant: {answer}\")\n",
        "        chat_history.append((question, answer))\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
